{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# for NLP interpretation\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "\n",
    "# import own scripts\n",
    "import sys\n",
    "sys.path.insert(0, '/src/')\n",
    "\n",
    "%autoreload 2\n",
    "from utils import format_raw_documents, myNLP, merge_2_string_lists, get_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available CPU cores: \n",
      "4\r\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of available CPU cores: \")\n",
    "!sysctl -n hw.ncpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook functions\n",
    "def parallelize(function, tasks, workers=4):\n",
    "    '''\n",
    "    Performs a task as defined by `function` in parallel and returns the result.\n",
    "    '''\n",
    "    if __name__ == '__main__':\n",
    "        with Pool(processes=workers) as p:\n",
    "            results = list(tqdm_notebook(p.imap(function, tasks), total=len(tasks)))   \n",
    "        return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142616</th>\n",
       "      <td>9/9/2015</td>\n",
       "      <td>oil prices up in asian trad</td>\n",
       "      <td>Singapore: Oil prices edged higher in quiet As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142617</th>\n",
       "      <td>9/9/2015</td>\n",
       "      <td>cost of quaid e azam solar power project cut b...</td>\n",
       "      <td>LAHORE: Putting  stout defence of the solar po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142618</th>\n",
       "      <td>9/9/2015</td>\n",
       "      <td>china pakistan set to sign cpec zone d</td>\n",
       "      <td>KARACHI: Pakistan is set to sign a 40-year-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142619</th>\n",
       "      <td>9/9/2016</td>\n",
       "      <td>Global airport traffic 64 percent 2015 fastest...</td>\n",
       "      <td>strong&gt;MONTREAL: Global airport traffic grew a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142620</th>\n",
       "      <td>9/9/2016</td>\n",
       "      <td>Taxpayers directory to be launched today</td>\n",
       "      <td>strong&gt;ISLAMABAD: Finance Minister Ishaq Dar w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                                              Title  \\\n",
       "142616  9/9/2015                        oil prices up in asian trad   \n",
       "142617  9/9/2015  cost of quaid e azam solar power project cut b...   \n",
       "142618  9/9/2015             china pakistan set to sign cpec zone d   \n",
       "142619  9/9/2016  Global airport traffic 64 percent 2015 fastest...   \n",
       "142620  9/9/2016           Taxpayers directory to be launched today   \n",
       "\n",
       "                                                  Content  \n",
       "142616  Singapore: Oil prices edged higher in quiet As...  \n",
       "142617  LAHORE: Putting  stout defence of the solar po...  \n",
       "142618  KARACHI: Pakistan is set to sign a 40-year-lea...  \n",
       "142619  strong>MONTREAL: Global airport traffic grew a...  \n",
       "142620  strong>ISLAMABAD: Finance Minister Ishaq Dar w...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load news articles\n",
    "a1 = pd.read_csv('data/Articles.csv', encoding = \"ISO-8859-1\")\n",
    "a2 = pd.read_csv('data/all-the-news/articles1.csv', encoding = \"ISO-8859-1\")\n",
    "a3 = pd.read_csv('data/all-the-news/articles2.csv', encoding = \"ISO-8859-1\")\n",
    "a4 = pd.read_csv('data/all-the-news/articles3.csv', encoding = \"ISO-8859-1\")\n",
    "raw_documents = [a1, a2, a3, a4]\n",
    "\n",
    "# Format\n",
    "docs = format_raw_documents(raw_documents)\n",
    "\n",
    "# Clear memory\n",
    "del a1, a2, a3, a4, raw_documents\n",
    "\n",
    "docs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "> 1. Merge `Title` & `Content`\n",
    "> 2. Prep text. I set-up to run in parallel and it's much faster but still takes ~7 minutes on my laptop.\n",
    "> 3. Perform Sentiment Analysis using `TextBlob`. May take ~150 hours to run in parallel on my machine. A powerful AWS instance with 64 cores will still take ~9 hours to run. The best approach to optimize performance here is to use convert to **C** code using `Cython` and possibly even use distributed computing.\n",
    "\n",
    "**Next: try optimizing code for efficiency using `Dask` and `Cython`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate `myNLP` object\n",
    "myNLP = myNLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cb0349adcd475abe50e250392844d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=142619), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# merge `Topics` and `Content`\n",
    "merged = merge_2_string_lists(docs['Title'], docs['Content'])\n",
    "\n",
    "# clean and prep text\n",
    "parallel_tasks = merged\n",
    "parallel_func = myNLP.prep_docs_lematize\n",
    "docs['Processed Text'] = parallelize(parallel_func, merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66edc50f4f9d42f497cfd1015fee606a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=142619), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-7:\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/dastanaitzhanov1/CloudStation/Job Search/2018/HyperGiant/HG/utils.py\", line 291, in get_sentiment\n",
      "    return opinion.sentiment.p_pos, opinion.polarity, opinion.subjectivity\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\", line 24, in __get__\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/blob.py\", line 426, in sentiment\n",
      "    return self.analyzer.analyze(self.raw)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 88, in analyze\n",
      "    super(NaiveBayesAnalyzer, self).analyze(text)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/base.py\", line 94, in analyze\n",
      "    self.train()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\", line 35, in decorated\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 81, in train\n",
      "    self._classifier = nltk.classify.NaiveBayesClassifier.train(train_data)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/classify/naivebayes.py\", line 212, in train\n",
      "    count = feature_freqdist[label, fname].N()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/probability.py\", line 124, in N\n",
      "    self._N = sum(self.values())\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/dastanaitzhanov1/CloudStation/Job Search/2018/HyperGiant/HG/utils.py\", line 291, in get_sentiment\n",
      "    return opinion.sentiment.p_pos, opinion.polarity, opinion.subjectivity\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\", line 24, in __get__\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/blob.py\", line 426, in sentiment\n",
      "    return self.analyzer.analyze(self.raw)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 88, in analyze\n",
      "    super(NaiveBayesAnalyzer, self).analyze(text)\n",
      "  File \"/Users/dastanaitzhanov1/CloudStation/Job Search/2018/HyperGiant/HG/utils.py\", line 291, in get_sentiment\n",
      "    return opinion.sentiment.p_pos, opinion.polarity, opinion.subjectivity\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\", line 24, in __get__\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/base.py\", line 94, in analyze\n",
      "    self.train()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\", line 35, in decorated\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/blob.py\", line 426, in sentiment\n",
      "    return self.analyzer.analyze(self.raw)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 79, in train\n",
      "    nltk.corpus.movie_reviews.words(fileids=[f])), 'pos') for f in pos_ids]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 88, in analyze\n",
      "    super(NaiveBayesAnalyzer, self).analyze(text)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 79, in <listcomp>\n",
      "    nltk.corpus.movie_reviews.words(fileids=[f])), 'pos') for f in pos_ids]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/base.py\", line 94, in analyze\n",
      "    self.train()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 49, in _default_feature_extractor\n",
      "    return dict(((word, True) for word in words))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\", line 35, in decorated\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 49, in <genexpr>\n",
      "    return dict(((word, True) for word in words))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 77, in train\n",
      "    nltk.corpus.movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/util.py\", line 296, in iterate_from\n",
      "    tokens = self.read_block(self._stream)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 77, in <listcomp>\n",
      "    nltk.corpus.movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/plaintext.py\", line 122, in _read_word_block\n",
      "    words.extend(self._word_tokenizer.tokenize(stream.readline()))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 49, in _default_feature_extractor\n",
      "    return dict(((word, True) for word in words))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/data.py\", line 1166, in readline\n",
      "    line0withoutend = lines[0].splitlines(False)[0]\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 49, in <genexpr>\n",
      "    return dict(((word, True) for word in words))\n",
      "KeyboardInterrupt\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/util.py\", line 296, in iterate_from\n",
      "    tokens = self.read_block(self._stream)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/plaintext.py\", line 122, in _read_word_block\n",
      "    words.extend(self._word_tokenizer.tokenize(stream.readline()))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/tokenize/regexp.py\", line 129, in tokenize\n",
      "    return self._regexp.findall(text)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/dastanaitzhanov1/CloudStation/Job Search/2018/HyperGiant/HG/utils.py\", line 291, in get_sentiment\n",
      "    return opinion.sentiment.p_pos, opinion.polarity, opinion.subjectivity\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\", line 24, in __get__\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/blob.py\", line 426, in sentiment\n",
      "    return self.analyzer.analyze(self.raw)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 88, in analyze\n",
      "    super(NaiveBayesAnalyzer, self).analyze(text)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/base.py\", line 94, in analyze\n",
      "    self.train()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\", line 35, in decorated\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\", line 81, in train\n",
      "    self._classifier = nltk.classify.NaiveBayesClassifier.train(train_data)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/classify/naivebayes.py\", line 225, in train\n",
      "    probdist = estimator(freqdist, bins=len(feature_values[fname]))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/probability.py\", line 891, in __init__\n",
      "    LidstoneProbDist.__init__(self, freqdist, 0.5, bins)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/probability.py\", line 781, in __init__\n",
      "    self._N = self._freqdist.N()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/nltk/probability.py\", line 124, in N\n",
      "    self._N = sum(self.values())\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a349b2868c80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparallel_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Processed Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mparallel_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-ec98ea2860da>\u001b[0m in \u001b[0;36mparallelize\u001b[0;34m(function, tasks, workers)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    929\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# perform Sentiment Analysis\n",
    "parallel_tasks = docs['Processed Text']\n",
    "parallel_func = get_sentiment\n",
    "docs['Sentiment'] = parallelize(parallel_func, parallel_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = docs['Processed Text'][0]\n",
    "sentiment_p_pos, polarity, subjectivity = get_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999992782957725\n",
      "sindh govt decides cut public transport fare 7pc kti rej karachi sindh government decided bring public transport fare 7 per cent due massive reduction petroleum product price federal government geo news reported source said reduction fare applicable public transport rickshaw taxi mean traveling meanwhile karachi transport ittehad kti refused abide government decision kti president irshad bukhari said commuter charged lowest fare karachi compare part country adding 80pc vehicle run compressed natural gas cng bukhari said karachi transporter cut fare decrease cng price made\n"
     ]
    }
   ],
   "source": [
    "from textblob import Blobber\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "tb = Blobber(analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "print(tb(text).sentiment.p_pos)\n",
    "print(tb(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "opinion = tb(text)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.048214285714285716"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Top #1 topic (NMF)\n",
      "1 Top #2 topic (NMF)\n",
      "2 Top #3 topic (NMF)\n",
      "3 Top #4 topic (NMF)\n",
      "4 Top #5 topic (NMF)\n"
     ]
    }
   ],
   "source": [
    "def add_top_5_topics(docs, top_5_topics_NMF):\n",
    "    '''\n",
    "    Adds top 5 topics in separate columns to the `docs` dataframe.\n",
    "    '''\n",
    "    for i, n in enumerate(range(1,6)):\n",
    "        col_name = 'Top #{} topic (NMF)'.format(str(n))\n",
    "        docs[col_name] = top_5_topics_NMF[i]\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
